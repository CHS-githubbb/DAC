#include "pch.h"
#include "Layers.h"
#include "Layers.cpp"
#include <iostream>


using namespace Layers;




/************************************
Lenet5 architecture:

data:			layser:

1x32x32	   
		   \		
			    conv 6x5x5
		   /
6x28x28
		   \
				max_pool
		   /
6x14x14			sigmoid
		   \
				conv 16x5x5
		   /
16x10x10
		   \
				max_pool
		   /
16x5x5			sigmoid
		   \
				fc 120x5x5
		   /
120x1x1
		   \
				fc 84x1x1
		   /
84x1x1			sigmoid
		   \
				fc 10x1x1
		   /
10x1x1

************************************/



typedef double dtype;
const int batch_size = 1;




//data area
dtype input[batch_size][1][28][28] = { {{{ 5.3519e-01, -1.1573e+00, -1.8456e+00, -1.3282e+00, -2.0582e-01,
		   -6.8123e-01, -3.3653e-01, -1.0078e+00,  4.4342e-01,  4.7399e-01,
			1.9154e+00,  4.2456e-01, -5.7525e-01,  8.8567e-01, -8.9125e-01,
		   -2.1917e+00, -4.9432e-01, -1.8389e+00,  2.5969e+00,  1.1985e-01,
		   -1.3972e+00,  2.6050e+00,  9.3947e-01,  9.9488e-01, -1.7383e+00,
		   -2.3482e+00, -9.6244e-01, -5.5314e-02},
		  { 1.6132e+00, -2.3190e+00,  4.7082e-01, -6.0801e-01, -6.1564e-01,
		   -2.2926e-01,  8.2606e-02, -3.8918e-01,  9.4567e-01, -1.1213e+00,
		   -4.4465e-01,  6.4175e-01, -9.6911e-01, -1.2019e+00,  1.3246e-01,
			1.4163e+00,  2.3265e-01, -8.7685e-01, -2.6465e-01,  1.1845e+00,
			2.8134e+00, -1.1841e+00, -5.4781e-01,  1.7510e+00,  3.9955e-01,
		   -2.7356e-01, -1.2649e+00, -3.1998e-02},
		  {-6.3667e-01,  9.4556e-01, -8.5650e-01,  7.7515e-01,  1.0757e+00,
		   -6.9531e-01,  2.6545e+00, -1.0084e+00,  8.8542e-02,  1.6055e-01,
			6.7976e-01,  3.3262e-01,  4.3714e-01,  1.5613e+00, -8.6578e-01,
			2.1669e-01,  1.9077e+00,  2.5304e-01,  2.1978e+00, -7.2029e-01,
		   -2.6568e-01,  1.5529e-02,  1.1709e-01,  3.6717e-01,  4.8478e-01,
			1.7593e+00,  1.1558e+00,  3.5670e-01},
		  {-7.9561e-01,  4.8763e-01,  4.4829e-01, -8.5677e-01,  1.6209e+00,
		   -1.1128e+00,  2.2668e-01,  9.8501e-01,  8.1418e-01, -1.0765e+00,
			2.9321e-01, -1.9127e-01, -1.9293e+00, -1.3162e+00, -1.1428e-02,
		   -8.4089e-01,  1.8104e+00,  6.0351e-02,  1.3601e+00, -2.9661e-01,
			8.0091e-02, -1.9579e+00,  1.5553e+00,  4.0838e-01, -2.3095e-01,
			3.5421e-01, -8.4864e-01,  7.3426e-01},
		  { 4.0835e-01,  2.7218e-01, -1.9770e+00, -4.9625e-02, -9.7368e-01,
			4.8077e-01,  1.3885e+00, -7.3250e-01,  5.8684e-01, -1.1566e+00,
		   -7.5326e-01,  9.8754e-01,  2.0526e-01, -1.0140e-01,  6.3401e-01,
		   -5.1774e-01, -2.5999e-02,  1.2316e+00,  1.6954e+00, -8.4895e-01,
			9.0504e-01,  6.1337e-01, -1.0136e+00,  1.7933e+00, -9.4816e-01,
		   -9.5123e-02,  8.4859e-01, -4.0079e-01},
		  { 6.1942e-02,  9.3023e-01, -5.4305e-02,  1.9371e-02, -9.0296e-01,
			1.3070e-01,  7.0255e-01, -1.1216e+00,  1.6797e-02, -1.1179e+00,
			1.4591e-02,  1.7967e-01, -1.1101e+00, -9.7586e-02, -1.3734e+00,
		   -1.6805e+00, -7.9182e-01,  1.2314e+00,  1.2355e-01, -6.6720e-01,
		   -7.5936e-02,  1.6084e+00, -1.3134e+00,  9.6444e-01, -2.8545e-01,
			1.1347e+00,  9.9714e-01,  2.3389e-01},
		  { 4.1646e-01,  7.5191e-01, -6.2607e-01, -1.0518e+00, -5.2628e-01,
			1.7490e+00, -8.5019e-01,  7.5589e-01, -8.8776e-01, -1.0905e+00,
			1.4237e+00, -1.3063e+00, -1.0832e+00, -2.4382e+00, -1.3186e+00,
			1.1760e+00,  1.0632e+00, -6.7894e-01, -4.3511e-02,  1.1708e+00,
		   -6.0159e-01, -4.8512e-01, -4.9246e-01, -1.6588e+00,  5.2155e-02,
			4.5428e-01,  1.2312e+00,  1.3822e-01},
		  { 1.1731e+00,  1.8747e+00,  7.5816e-01, -9.6996e-01, -2.1763e-01,
		   -2.1071e+00,  2.8104e-02,  2.4957e-01, -5.2895e-01,  4.5301e-01,
			1.6829e-01, -1.0290e+00,  1.0103e+00,  2.7910e+00,  7.0589e-01,
			3.4543e-01, -3.4515e-02, -1.5092e+00, -6.9915e-01,  7.1340e-01,
		   -1.8681e+00, -3.4525e-01,  3.4112e-01, -6.3155e-01,  1.4494e-01,
			6.6009e-01, -8.2991e-01,  1.5612e-01},
		  {-9.8790e-01, -4.2534e-02, -3.2871e-01,  1.4985e+00, -5.4536e-01,
			4.9956e-01,  5.8851e-01,  2.9554e+00, -3.3744e-01,  1.0952e-01,
		   -4.9729e-01,  7.2092e-02, -8.7560e-02,  4.9061e-01,  1.3889e+00,
			7.7748e-01,  1.8046e+00,  3.3172e-01, -2.9510e-01,  3.5597e-01,
			8.9901e-01,  5.9274e-01,  9.7491e-01,  1.8040e-01, -5.7046e-01,
			3.4048e-01,  4.9044e-01,  9.7715e-01},
		  { 1.4064e-01, -1.5001e+00, -1.4809e+00,  1.0152e+00, -7.1991e-01,
		   -4.1712e-01, -5.0515e-01, -4.4396e-01,  2.2119e+00,  8.6073e-01,
			6.0081e-01, -6.4509e-01, -1.6918e+00,  2.5551e-01,  3.9631e-01,
			8.4115e-01, -1.8552e+00,  1.8526e+00, -9.2121e-01,  3.2588e-01,
			1.2907e-01,  5.1467e-02,  6.5142e-01, -4.2542e-01, -6.1185e-01,
		   -1.5556e+00, -8.4397e-02,  9.2945e-01},
		  { 1.3461e+00, -3.3033e-01,  1.1740e-01,  5.0549e-01,  1.4341e+00,
			8.1527e-01,  7.4212e-01,  2.8785e-01, -6.5233e-01,  1.8510e+00,
		   -6.2979e-01,  4.8774e-01,  3.5250e-01,  1.8632e-01,  3.1497e-01,
			5.9342e-01,  2.0319e-01, -1.2425e-01, -1.0755e+00, -1.5361e-02,
		   -6.5866e-01, -9.8451e-01,  1.1784e+00, -6.5770e-01,  6.9231e-01,
		   -2.8619e-01,  3.3137e-01, -4.4276e-01},
		  {-1.0070e-01,  4.7355e-02,  1.4808e+00,  5.8105e-01,  5.0198e-01,
		   -2.0633e-01,  5.3054e-01,  5.8039e-01,  2.9799e-01,  2.4287e-01,
		   -3.3017e-02, -8.7031e-02,  5.4785e-01,  9.5338e-01,  7.2034e-01,
		   -1.2062e+00,  4.0557e-01,  1.5026e+00, -1.8457e-01,  7.0557e-01,
		   -2.6575e-01,  3.5777e-01, -1.8962e+00, -4.7512e-01,  7.6770e-01,
			1.7063e+00,  1.2696e+00,  2.2120e+00},
		  {-7.7414e-01, -1.7901e+00,  2.7757e-01, -1.2886e+00, -1.4655e+00,
		   -4.5820e-01, -1.5667e+00,  6.1064e-01,  1.0899e+00,  2.9623e-01,
		   -1.4183e+00,  2.2331e-02, -6.3586e-01, -6.3226e-01,  9.7157e-01,
		   -8.0457e-01,  3.4290e-01, -1.7871e+00,  6.9622e-01, -1.0068e+00,
			8.1719e-01,  3.5523e-02, -1.3940e+00, -4.1954e-01, -3.6757e-02,
			7.9930e-01, -1.0404e+00,  7.6536e-01},
		  {-5.0841e-01,  3.7693e-01, -3.2513e-01,  2.2026e+00,  1.1223e+00,
		   -5.8458e-01,  1.5812e+00,  9.3610e-01, -4.1336e-01,  1.2122e+00,
		   -3.3075e-01,  3.3261e-01, -7.0057e-01,  2.6819e-01,  1.4127e+00,
		   -7.8957e-01,  9.3169e-01,  5.9414e-01, -9.2950e-01, -3.3779e-01,
			1.4992e-01,  2.0549e-01, -1.4130e+00,  1.0971e-01, -7.7628e-01,
			6.8039e-01,  7.7658e-02, -1.3297e+00},
		  {-6.7087e-01, -9.2865e-01,  6.5268e-01, -4.6928e-01,  1.6322e+00,
			8.8550e-02, -1.0129e+00,  8.2670e-01,  1.2047e+00,  1.3639e+00,
		   -1.3139e-02,  5.1933e-01, -3.1240e-01,  3.8890e-01, -1.4987e-01,
			2.8856e-01, -1.8078e-01, -1.4664e-02, -3.8384e-01,  1.7820e+00,
		   -7.2588e-01,  6.0961e-01,  1.2555e+00, -5.0392e-01,  1.2445e+00,
			1.3562e-01,  1.2692e-01, -7.3342e-01},
		  {-1.9229e-01,  5.2816e-03,  1.0347e+00,  1.2434e+00,  2.3788e+00,
			6.1668e-01,  3.5824e-01,  7.7668e-01,  1.4121e-02,  1.1159e+00,
			4.2233e-01,  4.7384e-01, -1.2253e+00,  9.1760e-02,  1.0090e+00,
			4.4184e-01, -1.7161e-01,  9.5927e-01, -1.4619e-01, -1.4485e+00,
			7.5928e-01,  3.4415e-01, -4.4162e-01,  4.1457e-01, -1.5063e+00,
		   -9.4890e-01, -5.0882e-01,  2.0212e-01},
		  {-1.1723e+00, -8.3587e-01, -7.6492e-02, -1.1483e-01, -1.0491e+00,
			4.3792e-01, -3.8382e-01,  1.1566e+00,  7.5779e-01,  1.2154e+00,
		   -2.7060e-01, -8.3769e-01,  1.0779e+00, -3.5995e-01,  1.0090e+00,
			1.8777e+00,  1.0518e+00,  1.4585e+00,  1.9803e+00,  1.3063e+00,
		   -7.1929e-01,  1.4547e+00, -9.1545e-01, -5.9257e-01, -4.6083e-01,
			9.8706e-01, -8.8614e-01, -8.8141e-01},
		  { 9.3735e-01,  5.7164e-01,  1.1886e-03,  6.6366e-01,  7.6689e-01,
			7.3976e-02, -3.8848e-02,  6.2516e-01,  1.1922e-01,  1.2917e+00,
		   -7.9614e-01,  1.1827e+00,  8.7685e-01, -1.1465e-01, -3.5349e-01,
			1.5718e+00, -1.5259e-01, -1.2745e+00,  9.8477e-01,  8.4871e-01,
		   -1.0337e+00, -1.3319e+00,  2.7098e-01,  1.4067e+00,  2.2404e-01,
			2.5213e-01, -7.6598e-01,  2.7500e-01},
		  { 1.1654e-01,  9.5918e-01,  1.0956e+00, -3.1875e-02,  1.0308e+00,
		   -1.2583e+00,  1.0887e+00, -7.3872e-01, -2.0382e-01, -5.8400e-01,
		   -2.0817e+00,  7.6142e-01,  9.5424e-01, -1.1630e+00, -3.3864e-01,
			6.9889e-01,  9.7343e-01,  1.4966e-01, -7.4972e-01, -3.2221e-02,
			9.0176e-01, -2.2018e-01, -6.9787e-01, -6.2046e-01,  4.4880e-02,
			6.7588e-01, -5.2644e-01,  1.2257e+00},
		  {-3.6463e-01,  4.6451e-01, -1.0910e+00, -8.4427e-01,  1.1425e+00,
			5.3010e-01, -2.9455e-01,  1.0329e+00, -2.0664e+00,  1.7406e-01,
			3.5513e-01,  3.6100e-01,  2.1360e+00,  6.6453e-01, -2.6297e-01,
			5.7071e-01, -5.7983e-01, -1.1798e+00, -1.4232e+00,  1.3823e+00,
		   -2.2754e-02, -1.5842e+00, -7.8031e-01, -8.5510e-01, -9.8067e-01,
		   -1.5366e+00, -1.8258e+00, -1.6066e+00},
		  {-5.1720e-01,  1.8591e+00, -3.7685e-01,  1.5582e-01,  7.3630e-01,
		   -5.6689e-01, -7.4518e-01, -4.0671e-01, -1.8222e+00,  2.7936e-01,
			1.1890e+00,  5.2132e-01,  8.0565e-02,  4.2693e-01,  8.2870e-01,
			6.5860e-01, -5.9807e-02,  6.2948e-01, -8.7386e-01,  3.5687e-01,
			3.8488e-03, -1.4462e+00,  1.9697e+00, -1.2689e+00,  4.7003e-01,
		   -2.3789e-01, -9.4903e-01, -4.1229e-02},
		  { 1.1229e+00, -8.8405e-01, -1.4929e+00,  5.6801e-01, -1.8646e+00,
			1.8530e+00,  1.0744e+00, -1.0457e+00,  1.3219e+00, -9.1454e-01,
			3.9814e-02,  1.0209e+00,  3.6974e-01,  5.1848e-01, -7.0128e-01,
		   -3.5281e-01,  2.9948e-02, -1.9042e+00,  1.3222e-01,  1.1220e-01,
		   -1.7450e+00, -1.5720e+00, -1.6295e+00, -1.4880e+00, -1.3352e+00,
			2.0154e+00, -9.5129e-01, -1.6130e-01},
		  { 9.8798e-01,  1.3323e+00, -1.8472e+00, -7.4371e-01, -6.2880e-01,
		   -9.1237e-01, -5.1451e-02,  1.0901e-02, -6.1945e-01,  1.4737e+00,
		   -9.6123e-01,  7.6446e-01, -1.9201e+00,  7.7502e-01,  1.0018e+00,
		   -1.2732e+00,  9.9160e-01, -6.1489e-01, -8.2517e-01, -9.3817e-01,
		   -1.2082e-02,  2.3876e-01, -1.7002e+00, -1.0223e+00, -4.3781e-01,
		   -2.9715e-01,  5.8292e-01,  1.9705e-01},
		  { 4.5527e-01,  1.4024e+00,  2.2406e+00, -1.7017e+00,  7.4772e-01,
		   -1.1573e+00, -1.5485e+00, -1.0104e-01, -4.1392e-01, -1.4278e+00,
		   -1.2712e+00,  1.3863e+00,  2.7903e-01, -8.0232e-01,  5.6682e-01,
			1.2838e-01, -8.1746e-01, -1.6844e+00, -1.4638e+00,  6.1379e-01,
			3.8853e-01,  1.3774e+00, -5.3377e-01, -1.2209e+00,  6.8038e-01,
			7.0235e-01, -3.9421e-01,  6.4197e-01},
		  { 4.7795e-01, -5.6414e-01,  6.1938e-01, -3.0059e-01, -6.3334e-01,
		   -4.2848e-01,  7.3633e-01,  3.1338e-01, -1.4334e+00,  2.8737e-01,
			1.8815e-03,  4.5764e-01, -1.8349e-01, -2.4969e+00,  1.4053e+00,
			9.5414e-01,  1.1118e+00, -2.0225e-01,  1.2208e+00, -2.3266e-01,
		   -1.1018e+00, -4.1690e-02, -7.0351e-01, -1.1896e+00,  1.3497e+00,
			1.5145e+00,  1.9097e+00,  4.8852e-01},
		  { 1.7481e-02, -9.2853e-01, -1.8149e+00,  3.6081e-01,  7.8264e-01,
		   -4.2595e-01, -1.0805e+00,  3.2630e-01,  8.9680e-01,  8.8265e-01,
			9.5717e-01, -3.8666e-01, -5.8003e-01,  8.7043e-01, -9.6576e-01,
		   -7.2269e-01, -5.6800e-01,  4.7254e-02,  2.5141e-01, -1.1612e-01,
			3.8277e-01, -6.8379e-01, -1.1135e+00, -1.6351e+00,  2.4186e-01,
			6.8727e-01, -1.0934e+00, -1.7118e-01},
		  {-6.5032e-01,  2.8329e-01,  1.8974e+00, -1.6166e+00,  1.3517e-01,
			1.1922e+00,  1.2569e+00,  8.6425e-01,  1.9783e+00,  4.9960e-01,
		   -1.4503e+00, -2.2329e-01, -7.2002e-01, -4.5997e-01,  7.1517e-01,
			5.7380e-01, -1.1917e-01,  4.6378e-01, -1.8035e+00, -1.5561e+00,
		   -1.4751e-01, -9.0327e-01, -1.2180e-01, -4.3288e-01, -8.2917e-01,
			6.0925e-02,  8.8778e-01, -1.3467e-01},
		  { 1.0246e+00,  7.2084e-01, -1.1036e+00,  9.9832e-01,  1.2797e+00,
			9.0316e-01, -1.0208e+00,  7.6721e-01,  8.1313e-02, -1.2748e+00,
			2.4145e+00, -2.6811e+00, -1.1925e+00,  1.5607e+00, -1.6848e+00,
			1.8980e-01, -2.2614e+00,  5.6259e-01,  1.9972e+00,  1.9724e+00,
		   -1.7250e+00, -2.4613e+00, -1.0275e+00, -1.7124e-01,  6.1339e-01,
		   -1.7740e+00, -7.7908e-01,  8.5155e-01}}} };


dtype c1[batch_size][6][28][28];
dtype s2[batch_size][6][14][14];
dtype c3[batch_size][16][10][10];
dtype s4[batch_size][16][5][5];
dtype f5[batch_size][120][1][1];
dtype f6[batch_size][84][1][1];
dtype f7[batch_size][10][1][1];

/*
features.0.weight : torch.Size([6, 1, 1, 1])
features.0.bias : torch.Size([6])
features.3.weight : torch.Size([16, 6, 5, 5])
features.3.bias : torch.Size([16])
classifier.0.weight : torch.Size([120, 400])
classifier.0.bias : torch.Size([120])
classifier.2.weight : torch.Size([84, 120])
classifier.2.bias : torch.Size([84])
classifier.3.weight : torch.Size([10, 84])
classifier.3.bias : torch.Size([10])
*/


extern dtype
	features_0_weight[6][1][1][1], features_0_bias[6],
	features_3_weight[16][6][5][5], features_3_bias[16],
	classifier_0_weight[120][16][5][5], classifier_0_bias[120],
	classifier_2_weight[84][120][1][1], classifier_2_bias[84],
	classifier_3_weight[10][84][1][1], classifier_3_bias[10];

			

int main() {

	//std::cout << "link!" << std::endl;

	//all layers in Lenet5

	Conv<dtype, 6, 1, batch_size, 1, 28, 28> conv1(features_0_weight, features_0_bias);

	void (*max_pool2)(dtype [batch_size][6][28][28], dtype[batch_size][6][14][14]) 
			= MaxPool<dtype, 2, batch_size, 6, 28, 28, 2>;

	void (*relu_s2)(dtype [batch_size][6][14][14]) = ReLU<dtype, batch_size, 6, 14, 14>;

	Conv<dtype, 16, 5, batch_size, 6, 14, 14> conv3(features_3_weight, features_3_bias);

	void(*max_pool4)(dtype[batch_size][16][10][10], dtype[batch_size][16][5][5]) 
		= MaxPool<dtype, 2, batch_size, 16, 10, 10, 2>;

	void (*relu_s4)(dtype [batch_size][16][5][5]) = ReLU<dtype, batch_size, 16, 5, 5>;

	FullConnect<dtype, 120, batch_size, 16, 5, 5> fc5(classifier_0_weight, classifier_0_bias);

	void (*relu_s5)(dtype [batch_size][120][1][1]) = ReLU<dtype, batch_size, 120, 1, 1>;

	FullConnect<dtype, 84, batch_size, 120, 1, 1> fc6(classifier_2_weight, classifier_2_bias);

	FullConnect<dtype, 10, batch_size, 84, 1, 1> fc7(classifier_3_weight, classifier_3_bias);

	
	/*
	for (int i = 0; i < 1; ++i) {
		for (int j = 0; j < 28; ++j) {
			for (int k = 0; k < 28; ++k) {
				input[0][i][j][k] = 1;
			}
		}
	}
	*/
	

	
	

	//run Lenet5
	conv1(input, c1);
	max_pool2(c1, s2);
	relu_s2(s2);
	conv3(s2, c3);
	max_pool4(c3, s4);
	relu_s4(s4);
	fc5(s4, f5);
	relu_s5(f5);
	fc6(f5, f6);
	fc7(f6, f7);

	
	


	//check output

	for (int b = 0; b < batch_size; ++b) {
		for (int i = 0; i < 10; ++i) {
			for (int h = 0; h < 1; ++h) {
				for (int w = 0; w < 1; ++w) {
					std::cout << f7[b][i][h][w] << " ";
				}
			}
			std::cout << std::endl;
		}
		std::cout << std::endl;
	}
	
}

